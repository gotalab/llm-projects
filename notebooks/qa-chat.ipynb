{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3035f22-170f-448f-983c-a54780532bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27578d34-8f4b-4afc-92ab-64e82ddb463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_path = '/home/jovyan/settings/.env'\n",
    "# OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0517d397-a497-4eb5-ae72-4570b2f8c568",
   "metadata": {},
   "source": [
    "# QA and Chat over Documents\n",
    "https://python.langchain.com/docs/use_cases/question_answering/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a25b13-480f-4e3e-bddf-5878223474e1",
   "metadata": {},
   "source": [
    "## Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4cbe613-a963-499a-8227-ceae7c22f981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' スレッタ・マーキュリー'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "# Document loader\n",
    "loader = WebBaseLoader([\"https://g-witch.net/\"])\n",
    "# Index that wraps above steps\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])\n",
    "# Question-answering\n",
    "question = \"水星の魔女は誰ですか？名前のみ返してください。\"\n",
    "index.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64e37de3-bdfd-4667-97e3-0b57a781eea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\n機動戦士ガンダム 水星の魔女 公式サイト\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJavaScriptの設定を有効にしてください。\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMOBILE SUIT GUNDAM THE WITCH FROM MERCURY\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOfficial Twitter\\nLanguage\\n\\nLanguage\\n\\n\\n简体中文\\n繁體中文 (HK)\\n繁體中文 (TW)\\nภาษาไทย\\nEnglish\\nFrançais\\nItaliano\\n한국어\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n各種配信サービスにて配信中\\n\\n\\nファンメイドコンテンツ企画「みんなで応援プロジェクト」開催中 \\xa0\\n\\n\\n\\n\\n\\n8月6日 “水星の魔女フェス” 開催決定\\n            チケット先行抽選販売申し込み受付中\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nA.S.122――\\n                  数多の企業が宇宙へ進出し、巨大な経済圏を構築する時代。\\n\\n                  水星からアスティカシア高等専門学園に編入してきたスレッタ・マーキュリーは、\\n                  ミオリネ・レンブランの花婿として、株式会社ガンダムの一員として、出会いと刺激に満ちた学園生活を送ってきた。\\n\\n                  プラント・クエタでの事件から2週間。\\n                  スレッタは学園で、ミオリネとの再会を心待ちに日々を過ごす。\\n                  一方ミオリネはベネリットグループ本社に身を置き、父の容態を見守っていた。\\n                  二人に襲い来る新たな困難と、迫られる決断。\\n                  少女たちはそれぞれの想いを胸に、ガンダムがもたらす強大な呪いへと立ち向かっていく。\\n                                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n前日譚「PROLOGUE」各種配信サービスにて配信中\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                8月6日（日）開催決定！チケット先行抽選販売申し込み受付中！\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2023.07.02最終回放送記念！キャストコメントが到着\\n\\n\\n\\n\\n2023.06.307月2日（日）「Blu-ray vol.1 発売記念イベント」開催延期、及びライブ配信特別番組へのグエル・ジェターク役 阿座上洋平さん出演見合わせのお知らせ\\n\\n\\n\\n\\n2023.06.25制作上の都合による、一部サービスでの第24話配信遅延について\\n\\n\\n\\n\\n2023.06.23制作上の都合による、一部サービスでの第23話配信遅延について\\n\\n\\n\\n\\n2023.05.08『機動戦士ガンダム 水星の魔女』フェス ～アスティカシア全校集会～ 開催決定！（5月8日更新）\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n内容および画像の転載はお断りいたします。お問い合せ先はこちらをご覧ください。\\n\\n\\n\\n作品情報について\\n会社情報について\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          © 創通・サンライズ・MBS                  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://g-witch.net/', 'title': '機動戦士ガンダム 水星の魔女 公式サイト', 'description': '『機動戦士ガンダム 水星の魔女』各種配信サービスにて配信中', 'language': 'ja'})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"水星の魔女は誰ですか？名前のみ返してください。\"\n",
    "index.query(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2a2559-c83a-4e5e-b73d-b78e4c47c7aa",
   "metadata": {},
   "source": [
    "## 1. Loading, Splitting, Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27184f94-0d78-4726-a53a-07bb54fc50f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document loader\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader([\"https://lilianweng.github.io/posts/2023-06-23-agent/\"])\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60e2f4e7-6e3f-4fa2-8f4e-f42239aa00d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87e96839-b936-41cb-bc24-04dd5c131287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store \n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "vectorstore = Chroma.from_documents(documents=all_splits,embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efab941b-34cc-4916-95e9-99382faeaf1f",
   "metadata": {},
   "source": [
    "## 2. Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1191903-2028-4066-a407-da2661740010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "# len(docs)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd31bdc4-438b-42c9-b4c5-57024de3e47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llm-env/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "svm_retriever = SVMRetriever.from_documents(all_splits,OpenAIEmbeddings())\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "493f8ddb-a52b-46ef-b24d-79c85fae9f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. How can Task Decomposition be approached?', '2. What are the different methods for Task Decomposition?', '3. What are the various approaches to decomposing tasks?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultiQueryRetriever\n",
    "import logging\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "logging.basicConfig()\n",
    "logging.getLogger('langchain.retrievers.multi_query').setLevel(logging.INFO)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=vectorstore.as_retriever(),\n",
    "                                                  llm=ChatOpenAI(temperature=0))\n",
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "079b0865-cb9c-4fcc-89c8-7fffb21ee1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8945d31a-4631-45ca-897f-b163e0f73e0c",
   "metadata": {},
   "source": [
    "## 3. QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ae73a23-2789-44ba-8c50-edccaff4b9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the approaches to Task Decomposition?',\n",
       " 'result': 'The approaches to task decomposition include:\\n\\n1. Prompting with LLM: This approach involves using simple prompts to guide the model in decomposing the task into subgoals or steps. For example, the model can be prompted with instructions like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\"\\n\\n2. Task-specific instructions: In this approach, task-specific instructions are provided to the model to guide the task decomposition process. For example, if the task is to write a novel, the model can be instructed to \"Write a story outline\" as a step in the task decomposition.\\n\\n3. Human inputs: Task decomposition can also be done with the help of human inputs. Humans can provide guidance and input to the model in breaking down the task into smaller and simpler steps.\\n\\nIt\\'s important to note that the context does not provide any additional approaches to task decomposition beyond these three.'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectorstore.as_retriever())\n",
    "qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c22020a6-141c-4efa-851c-47790bad79ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The approaches to Task Decomposition include using simple prompting with LLM, task-specific instructions, and human inputs. Thanks for asking!'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n",
    "\n",
    "# Run chain\n",
    "from langchain.chains import RetrievalQA\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectorstore.as_retriever(),\n",
    "                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90158fa-355a-495e-84b4-ed21e1892d39",
   "metadata": {},
   "source": [
    "### Returning source documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "459b4a59-93ed-40e9-8ed0-36970147e92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=vectorstore.as_retriever(),\n",
    "                                       return_source_documents=True)\n",
    "result = qa_chain({\"query\": question})\n",
    "print(len(result['source_documents']))\n",
    "result['source_documents'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a056122a-81c5-4e01-bb25-976fb1cac5c8",
   "metadata": {},
   "source": [
    "### Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77186e04-d4fb-49ad-92d5-729fc634241e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the approaches to Task Decomposition?',\n",
       " 'answer': 'The approaches to Task Decomposition include:\\n1. Using LLM with simple prompting, such as providing steps or subgoals for achieving a task.\\n2. Using task-specific instructions, such as providing a specific instruction like \"Write a story outline\" for a writing task.\\n3. Incorporating human inputs in the task decomposition process.\\nAdditionally, the Chain of Thought (CoT) technique is a standard prompting technique that enhances model performance on complex tasks by instructing the model to \"think step by step\" and decompose tasks into smaller and simpler steps.\\nAnother approach is the Tree of Thoughts, which extends CoT by exploring multiple reasoning possibilities at each step and creating a tree structure.\\nSources: \\n- https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'sources': ''}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llm, retriever=vectorstore.as_retriever())\n",
    "result = qa_chain({\"question\": question})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e774546-c4a2-4cdb-8cf1-e69c86f3f673",
   "metadata": {},
   "source": [
    "### Customizing retrieved docs in the LLM prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e65c54f8-af2e-4785-ba98-584a62a3a727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'The approaches to task decomposition mentioned in the provided context are:\\n\\n1. Chain of thought (CoT): This approach involves instructing the language model to \"think step by step\" and decompose complex tasks into smaller and simpler steps. It enhances model performance on complex tasks by utilizing more test-time computation.\\n\\n2. Tree of Thoughts: This approach extends CoT by exploring multiple reasoning possibilities at each step. It decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS or DFS, and each state is evaluated by a classifier or majority vote.\\n\\n3. LLM with simple prompting: This approach involves using a language model with simple prompts like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\" to perform task decomposition.\\n\\n4. Task-specific instructions: This approach involves providing task-specific instructions to guide the task decomposition process. For example, using the instruction \"Write a story outline\" for writing a novel.\\n\\n5. Human inputs: Task decomposition can also be done with human inputs, where humans provide guidance and input to break down a task into smaller subtasks.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain({\"input_documents\": unique_docs, \"question\": question}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99b2f771-2f29-4445-82a1-8a1e21abb040",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm,retriever=vectorstore.as_retriever(),\n",
    "                                       chain_type=\"stuff\")\n",
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17aae4ce-451a-45aa-a768-a16ec209ba63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the approaches to Task Decomposition?',\n",
       " 'result': 'The approaches to task decomposition include:\\n\\n1. Prompting with LLM: This approach involves using simple prompts to guide the model in decomposing the task into subgoals or steps. For example, the model can be prompted with instructions like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\"\\n\\n2. Task-specific instructions: In this approach, task-specific instructions are provided to the model to guide the task decomposition process. For example, if the task is to write a novel, the model can be instructed to \"Write a story outline\" as a step in the task decomposition.\\n\\n3. Human inputs: Task decomposition can also be done with the help of human inputs. Humans can provide guidance and input to the model in breaking down the task into smaller and simpler steps.\\n\\nIt\\'s important to note that the context does not provide any additional approaches to task decomposition beyond these three.'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a0b226-e837-4e00-8ad7-c5262c02e327",
   "metadata": {},
   "source": [
    "## 4. Chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee5992b-21cc-438b-842f-e8b3d3930b28",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a988e91f-9017-4b6c-ae10-f0b7849ba95d",
   "metadata": {},
   "source": [
    "## 諸々調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8a2dea9-c6d5-4008-8819-b7373b147367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'シンシヤはどんなキャラクターですか？分からない場合は分からないと返してください。',\n",
       " 'answer': 'シンシヤはリムルの娘であり、大賢者の能力を持っています。また、捕食能力を持ち、他のモンスターの能力を多数獲得しています。\\n',\n",
       " 'sources': 'https://ten-sura-m.bn-ent.net/'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Document loader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "OPENAI_API_KEY=\"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\"\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "question = \"シンシヤはどんなキャラクターですか？分からない場合は分からないと返してください。\"\n",
    "references = [\"https://ten-sura-m.bn-ent.net/\"]\n",
    "\n",
    "def qa_with_source(llm, question, references):\n",
    "\n",
    "    loader = WebBaseLoader(references)\n",
    "    data = loader.load()\n",
    "    \n",
    "    # Split\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "    all_splits = text_splitter.split_documents(data)\n",
    "    \n",
    "    # Store \n",
    "    vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\n",
    "    \n",
    "    qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llm, chain_type=\"map_reduce\", retriever=vectorstore.as_retriever())\n",
    "    result = qa_chain({\"question\": question})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f03f1c8-16ca-4f12-b23c-6703d28f6f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  スレッタはどんなキャラクターですか？\n",
      "Answer:  スレッタは「機動戦士ガンダム 水星の魔女」のキャラクターであり、プロスペラたちとの決戦では、クワイエット・ゼロへの興味から同行を希望し、オーバーライド対策のアイディアを提供します。また、市ノ瀬加那がスレッタ・マーキュリー役を演じ、Lynnがスレッタの相棒であるミオリネ・レンブラン役を演じます。\n",
      "\n",
      "Sources:  \n",
      "- https://ja.wikipedia.org/wiki/%E6%A9%9F%E5%8B%95%E6%88%A6%E5%A3%AB%E3%82%AC%E3%83%B3%E3%83%80%E3%83%A0_%E6%B0%B4%E6%98%9F%E3%81%AE%E9%AD%94%E5%A5%B3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "def qa_with_source(llm: Any, question: str, references: List[str]) -> Dict[str, Any]:\n",
    "    \"\"\"Webからソースを拾ってきて回答を返すやつ。現状毎回ソース情報を取得し直すようにしているため、繰り返し処理には向いてないかも\n",
    "    \"\"\"\n",
    "    loader = WebBaseLoader(references)\n",
    "    data = loader.load()\n",
    "\n",
    "    # Split\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=10)\n",
    "    all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "    # Store\n",
    "    vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "    qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llm, chain_type=\"map_reduce\", retriever=vectorstore.as_retriever())\n",
    "    result = qa_chain({\"question\": question})\n",
    "    return result\n",
    "\n",
    "############# ここから入力 ################\n",
    "\n",
    "# OPENAI_API_KEY = \"sk-****\"\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "question: str = \"スレッタはどんなキャラクターですか？\"\n",
    "references: List[str] = [\"https://g-witch.net/\", \"https://ja.wikipedia.org/wiki/%E6%A9%9F%E5%8B%95%E6%88%A6%E5%A3%AB%E3%82%AC%E3%83%B3%E3%83%80%E3%83%A0_%E6%B0%B4%E6%98%9F%E3%81%AE%E9%AD%94%E5%A5%B3\"]\n",
    "\n",
    "############ ここまで入力 ################\n",
    "\n",
    "result = qa_with_source(llm, question, references)\n",
    "print('Question: ', result['question'])\n",
    "print('Answer: ', result['answer'])\n",
    "print('Sources: ', result['sources'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f27505-66b1-464b-964c-8a28539ffe4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
